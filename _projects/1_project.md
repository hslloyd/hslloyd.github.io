---
layout: page
title: Interface Design for Millions of Learners
description: The Usability of Quizlet as an XYZ for Students
img: assets/img/12.jpg
importance: 1
category: work
---

A qualitative and quantitative research project I conducted for my <i>Human Factors</i> course in undergrad. 

As technology automates many realms of our lives, certain systems in the education sphere are being technologically systemized through a plethora of software and hardware. When thinking of the classic technology in education: Spark Notes, Khan Academy, Google Docs, Easy Bib, and Quizlet are all often are reported being used. Each of these technologies are offer systems for students to study and learn more material in a faster timeframe. When I was a community college student, I often saw my peers specifically utilizing Quizlet to supplement for studying for exams, since they were often working multiple jobs etc. Due to the nature that the interface offers, Quizlet has seeped onto the computer tabs of most students. 


Quizlet is largely known for being an online flashcard system. Students know of it as a place to create flashcards and for studying them, and that in fact is the core of the technology’s founding. At the time that Quizlet was released to the public in 2005, it was the result of some code Andrew Sutherland’s, the founder, made to memorize animal names for his French class. Quizlet dominates society as it is used by two-thirds of high school students and half of university students in the United States (About Quizlet., n.d.). Quizlet’s mission is simply, “to help students (and their teachers) practice and master whatever they are learning. Quizlet provides engaging, customizable activities with contributions from people everywhere” (About Quizlet., n.d.). Quizlet is undoubtedly one the largest student and teacher online learning community. Every month, over 50 million active learners from 130 countries practice and master more than 300 million study sets of content on every subject and topic.  Although the usage is high, that doesn’t necessarily suggest that the system isn’t flawed. My group members and I all lamented on copious simple features that elicit negative valence on the user. We were motivated to use Quizlet as the interface to locate and expose these flaws that are currently in the user experience of most students in the United States today.    

While Quizlet has certainly developed in aesthetics, the home page is evidently not entirely reflective of the use of the user. As seen in Picture A1(see Appendix A for images of the Quizlet interface), the system’s features aren’t particularly salient, which enforces a system doesn’t present accurate information of its functions to the user. Since this interface relies heavily on user input, flexibility and accountability for diverse input would ought to be considered. As seen in Picture A2, the system doesn’t adjust correctly to a certain amount of information, limiting its use to a certain level of information to input.  As seen in Picture A3, A4, and A5, the environments for the user to interact with are filled with an excess of information, suggesting a feeling of fatigue and potentially restricting the user to use multiple features offered by the system. 

## User Requirements Interview 
In order to understand the frequent feature uses and experience of experienced Quizlet users, 9 individuals were interviewed (see Appendix B for further information on the User Requirements Interview). In understanding that the use of Quizlet is primarily for students, the demographics of the participants were recruited in terms of age, discipline, grade, and gender.	 Table 1 provides the extensive identities that each participant had, each offering unique and insight to our user requirements interview stage.
	The average age of the participants in the interviews to gather the user requirements was 25 with a standard deviation of 5.57. We had an eclectic array of ages that all used Quizlet in different conditions, demonstrating a decreased probability of cohort effects and useful interface design across ages. In addition to age, most of the participants were in different disciplines, ranging from Business, Chemistry, Earth Sciences, and Community & Legal studies, all portraying an independence of subject specific in the usage of Quizlet. The gender of our participants in this stage was 45% female and 55% male; given that our sample size was 9, this is somewhat representative of the population. Interestingly enough, while most participants were juniors in university, 20% were transfer and 20% were graduate students, demonstrating a usage of Quizlet’s interface across academic levels. The averaged self-reported expertise level, on a scale of 1 to 10, of the participants was 8.11, with a standard deviation of 0.928 (See Table 1). This represents that all of the participants had confidence in their expertise, and had a valid, consistent experience with Quizlet.  As stated above, Quizlet’s usage isn’t only by university students, it’s a frequent system for high school students. Given the limitations of recruiting for this project, none of the participants were in high school, thus the descriptions and conclusions can only be attributed to the representation of the participants. 
	In the interviews, participants consistently expressed how Quizlet supports them in the memorization of material across disciplines. Participants explained that a lot of classes are set up by offering key terms and testing them on the terms. Participant E stated that he finds quizlet useful for, “classes that offer a lot of memorization like biology, but not useful for classes like math, a flashcard does not do it for higher math.” Quizlet was reported as a dependable tool for practicing and preparing for recall. Aligned with this usage, participant C discussed a use of Quizlet outside of a school environment and as a tool used solely for memory in his profession. Participant C is an urban planner, and in working in government, especially a job with niche jargon, he used Quizlet to streamline the on boarding process for future supervisees. Participant C lamented on “how much time it took for me to learn these terms when I started, which limited me on my productivity.” Participant saw the inefficiency in spending time memorizing terms, which ultimately incentivized him to better that experience for future employees by streamlining with Quizlet.	 
Another core feature of Quizlet is the fuel for its system and the intended conceptual model via an interface metaphor of flashcards. Flashcards have been used to quickly learn terms in a time crunch in lieu of reading material multiple times. This model naturally attracts people who have time limitations: students who work. In the user requirements interviews, often participants expressed they would use Quizlet on public transit, in time between work and class, or while eating a meal. There also if a heavy decency on finding material from provided sets, participant C elaborated that he has “never created a set, 100% of my sets are my classmates.” This reflects that they weren’t otherwise able to set aside time to study and found a way to engage with their respective material through Quizlet. 
	As a group, we collectively shared a frequent scenario of using Quizlet, which was essentially to get the answers for online quizzes or homework assignments. Users of Quizlet will often upload the questions often generated by the textbook offered to instructors in their sets. Thus, when instructors post online quizzes or homework assignments based on the textbook material, students who copy-and-paste the question into google, are brought to a Quizlet set. Interestingly enough, even though students consistently google search and are brought to Quizlet, none of the participants stated that they would just simply go to Quizlet first. Even though we asked the participants questions that would enable them to discuss this use of Quizlet, we attribute a lack of this topic in the interviews as a result of social desirability bias. Participant C stated that, “most of my use is with searching of homework,” and participant D said that his only use of Quizlet was “to find answers for my online quizzes, but I didn’t learn much.” Participant D then went on to elaborate on the steps he would take to find the answer to the question: copying the question from the quiz, pasting it to good, and clicking the result that was offered by Quizlet. Participant D elaborated that he would click the Quizlet link since, “it was the textbook answers and it was consistently correct, and it would bring me other answers to my future quiz questions.” These descriptions supported the group’s idea on this use of this system, this supplying us with an area of examination. 
	In consideration with the participant’s report of Quizlet and of our own personal experience with this interface, we extracted three main tasks to evaluate with a new group of participants. We limited the evaluation into three tasks of interest (See Appendix C for more information on User Evaluation Tasks). Task 1 was established in replication of participants techniques for fast and efficient use of setting up Quizlet in order to spend more time studying. Task 1 asked the participants to create a set of flashcards from a provided excel spreadsheet by importing the excel spreadsheet to a new set. Task 2 was established in replication of our group’s and a few participant’s interpretation of a highly frequent use of the interface: answering quiz and homework questions. In task 2 we gave them the question, what are some Gestalt grouping principles? and had them answer it. This was a niche question that we suspected, even if the user had taken a psychology course, it is so detailed that they would need to do some level of research to answer it.  Task 3 was established to replicate another use of efficiently preparing material for a course in order to study is and have the user engage with the material. In task 3, we told the user that they were in an Intro to Cognition course, known as Psych 20A at University of California, Santa. The user was instructed to search for a set from that course and to save, customize, and practice it via the matching feature on the interface. 

## User Evaluation Tasks 
At first, the provided task sheet for task 1 was of simple Spanish vocabulary, which proved to be very simple and efficient, but not representative to the experience of the users from our interviews. After 3 participants completed the evaluation with the Spanish vocabulary excel sheet, we started to provide participants with an excel sheet of key terms for a course on Sensation and Perception. These terms were more in depth, and representative of the type of sets the participants from the user requirements interviews and our group were familiar with.   The participants who had the Spanish vocabulary excel sheet, completed the task on average in 2:45 minutes. The participants who had the Sensation and Perception sets completed the task on average in 7:08 minutes (See Figure 1). This difference proved importance on the design for use of Quizlet since different lengths of text proved to be more difficult to make a set with.
	In this task, most participants glazed over the “import from word, excel, google docs etc.” button and simply just started to copy and paste the information from the excel sheet. Some participants even had to do the task twice, since they didn’t actually use the import function and defaulted to copying the terms and pasting them into Quizlet. After first selecting “create,” participant X instantly glanced over the “import from word, excel, google docs etc.” button, and stated, without hesitations or inquiry, “I kind of skipped over everything… I immediately go to this first thing here,” referring to the feature to manually enter a flashcard.  After participant X completed the task by copying and pasting each term and definition individually, the interviewer asked to him to import the excel sheet. This led the participant to press the correct button and copy-and-paste the key terms into the correct box, leading him to declare that he, “might have done that wrong...the way that it pasted doesn’t look right, I feel like it would’ve looked more structured.”  When instructed to try to use the excel sheet without copying each term individually and after exploring the interface again, participant Z’s reaction was, “I am going to add a diagram,” as his idea of the correct choice since it was “the first thing it says I can do.” He then realized that adding a diagram didn’t make sense and resulted in using ctrl + f (a shortcut to find a string on a page) the explicit word “import.”
In contrast to many participant’s experience missing the “import from word, excel, google docs etc.” button, after some time exploring on how to import, participant Y was one of the few who initially saw the import function, but insisted that, “if I was starting with excel that is what I would do, but I would like to just write them in.” Participant Y’s execution of this task wasn’t seamless, due to feedback from the interface of a misaligned copy-and-paste result, she asked if she could start again.
 	Interestingly enough, participant Z, intuitively used the tab function to “line everything up,” since “a lot of programs have a lot of problems if it’s not aligned.” After further exploration, he explicitly noticed the instructions of using tabs to note when to separate the cards, yet when he submitted the sets, the tabs didn’t effectively present the information on the flashcards and he resulted to working with the original copy-and-pasting, which lead him complete the task. Overall, participants congruently struggled with seeing feedback on whether the simple copy-and-paste mechanism would work and were left unaware that they could simply scroll down the page to see it had. Participant X just looked at the first flash card set and stated that it worked, but after the interviewer asked them to scroll down to check, he then saw that the cards were filled inconsistently, leading him to fix the format.
For this task, every participant explored different sets through different search engine techniques, leading them to eclectic information in relation to the question, what are the gestalt grouping principles. Participant X was one of the few participants to take the first step of this task by googling the question and looking specifically for the Quizlet website, which was our predicted task execution. After not finding the Quizlet website through results offered by google, participant X resulted in copy-and-pasting in the question to Quizlet’s search option. Most participants simply searched, “gestalt grouping principles,” or “gestalt.” Participant X entered the entire question, which is what was used in using google first to find the flashcard with the question on it. In doing this, he was given multiple “What Are Some Principles of Sustainability?” sets, which is completely unrelated to the topic presented to him. After clicking on the first set provided to him, he used ctrl + f for “gestalt” and found no results, leaving him “confused as to why it brought me here.” Participant X then proceeded to type in “gestalt,” in Quizlet’s search-bar, stating his initial search was “probably too specific.”  This led him to sets named “Gestalt,” and after a bit of exploration he said, “I should actually read them.” Implying that he expected for Quizlet to provide him with a clear definition as opposed to a conglomeration of information. After participant X recited the correct definition of gestalt grouping principles, he clarified that he would, “actually go to google at this point” instead of trusting the information provided through the sets. 
	Participant Z’s first response was to, “search, because I feel like that is something the internet can do these days.” Participant Z’s search of, “gestalt grouping principles,” lead him to only study sets causing him to say, “I don’t really want study sets, I want classes… because a class teaches in the traditions of the word.” After looking for classes, participant Z learned that actually “classes are something that won’t help me learn a new concept in Quizlet…the most useful place here are the study sets, because it has the word ‘gestalt’ on them.” After studying the sets, and reading the defining terms of the gestalt principles, participant Z stated twice in frustration that he, “still doesn’t know really what gestalt grouping principles are.”
	Most of the participants actively clicked on sets that were seemingly simple, and scares in text, suggesting only core information. Participant Y stated that she decided on the first set she went with since it seemed valid to her because the terms were simple. Participant Z and Y clicked on sets that were noted as belonging to a teacher. Participant Y stated that she chose a certain set since it was “made by a teacher, and since the other sets had more terms, this indicated that this set would provide quality information.” Even participant Y, who was able to state the principles back to me and an efficient search, still wasn’t full aware of the definition of gestalt grouping principles. 
	For task 3, participant X’s first step was to search “psych 20a” into the Quizlet search engine in expectation to find “someone who took the exact same class as me, or is in the class.” This lead participant X to see a set with “psych 20a” as a title along with a labelling UCSC.  This step of the task was pretty representative to most of the participants, with an exception of participant Z, who took a relatively long time to get the correct search terms into Quizlet. In deciding which set to use, participant X relied heavily on the portrayal of the user’s sets, which indicated that since they “made two sets already, they might be on top of it.” Most other participants were decisive in terms of a title the represented the class and noted the university. 
	To customize and copy the set to the account, participant X explored the page “to see what the different things are I can do [on their set].” This seamlessly let him customize and then informed him that all the information was copied to his account. Most participants were successful in adding the set to their own profile, but not all of the participants found it as easy. While participant X was trying to find a way to copy the set, she decided to return to the main page and stated, “I don’t’ know if I actually saved that.” After returning to the previous page, participant Y realized that she lost the first set that she had created, without any warning or feedback. 
	In practicing the matching game, participant X elaborated the he was “just trying to link the boxes to each other.” It took participant X a remarkable 36 seconds to complete the matching task, and when the interviewer inquired with him on what the definition of the first term was that he matched, he couldn’t recall. At the end of the matching game, participant X noted he was happy he got a badge, and that he could collect badges. When participant Y practiced with the matching, some of the cards in her set had images, making the format weird and confusing to interpret, similar to the format problem seen in Picture A2. 
The average rate of task completion for task 1 was 7:08 minutes with a standard deviation of 0.14 seconds. The average rate of this task was around 3:11 minutes with a standard deviation of about 0.11 seconds. The average rate of task completion was 6:04 minutes with a standard deviation of about 0.12 seconds (See Figure 1). After all participants completed each task, they reported on a scale of 1-to-7, an average positive valanced word rating of 5.44 with a standard deviation of 0.37. Indicating a lot of positive valanced words like fast, organized, and expected were strongly fitting to the interface. On the same scale, they rated negative valanced words as not being fit around 2.7 with a standard deviation of 0.49. This is in congruency with the indication that a lot of negative valanced words like complex, annoying, inconsistent as not fitting well to the interface (See Table 3 and Appendix D for more information on this User Experience Questionnaire). After everyone completed the tasks, some common words to describe Quizlet was “helpful, massive, content, and confused.” Additionally, 16% of the variance in average rate of task completion can be explained by the variance in the self-reported expertise level of Quizlet (R2 = 0.165, see Figure 2). In consideration of a sample size of 10, this indicates an interface that has an ease of learnability. 

## Summary of User Task Evaluations
Participants consistently struggled with task 1, demonstrating a weakness in the accurate connection between the user’s mental model of the interface’s metaphorical use of the term “import” and the system’s conceptual model. The metaphor in this feature is presented as a way to import in analogous with the physical action of importing goods (food, materials, etc. through ships, trains, planes); a form of bringing resources from another system to the current one. Participant’s mental model was evidently similar to many systems that utilize the term “import,” meaning bringing an entire file from one system to the current. Quizlet doesn’t accurately depict that interface metaphor since this feature doesn’t evidently offer that function, deceiving the users until they realize the mechanism required to copy-and-paste the information over.  While completing this task, participant Y stated that she was “struggling… this task was confusing,” thus asking to lower her report of expertise, depicting the effect an inaccurate interface metaphor has on the user and ultimately leading them to a lack of self-confidence within the system.
After completing task 2, none of the participants were entirely confident with their understanding of the concept of interest (gestalt grouping principles). Since this task was implemented to understand the frequented use of Quizlet as a search engine for questions, many participants seemed overwhelmed by how information was being presented to them. Ultimately many of them were demonstrating a level of fatigue from an overload of information. Participants consistently suggested they always looked for simpler sets of information, relative to the superfluous study sets offered to them. This is an issue of the mission of Quizlet versus the user experience of the system: Quizlet’s search engine ultimately matched the user with the title of the set-in regard to what string they searched. The presented search engine results depict that Quizlet prioritizes the user finding sets, rather than information. This then leads an interface weakness of mapping between the system and the real world. User’s expected to be able to use the search engine to get a layout familiar to them of information, but they were provided with flashcard sets that were difficult to used. In the real world, when looking for an answer to information, people default to mediums with a layout of text (i.e. textbooks, dictionaries, etc.), users don’t often look through flash cards to find an answer. In support of this flaw in mapping between system and the real world, participant Z stated he expected to find information from the class, not the sets, since the class feature matches his mental model of class, “where people learn new information.” Participant Z, and others, were surprised after struggling to find the information buried in a set. All of the users expected to find the information and have to weave through sets to get there. 
In task 3, participants were generally successful in finding the course of interest, indicating that the user’s expectation of finding a course was met. The system generally offered leeway for exploration of customizing a set, and most of the participants were able to do so in this manner. While it took a bit of time for users to complete this task, in observations this task seemed to be overall the most errorless.  


## Improvements for the Technology
Results from user’s ability to complete task 1 lead me to suggest a few improvements. Quizlet could be more user friendly by making the “import from word, excel, google docs etc.” feature more visible in the layout. The font size for this is really small and the color is very light, making this feature relatively invisible to the user. This feature has tremendous use, it’s a really fast and efficient way to create flashcards, which could make the user engage with the core function of Quizlet: studying the material. Another suggestion to remediate the usage of this feature, would be to engineer a system that would let users upload and actually import from a different system. The mechanism implemented now lead the “imported” content to appear misaligned, indirectly having the user perceive feedback that they aren’t importing the content correctly. The “tab” system should be erased due to the confusion it brought to the participants. It proved to intuitively make sense and was demonstrated as a natural step in separating the terms for an import, it ultimately disrupted the alignment of the content, which left the confusing. This can be solved with the same recommendation of changing the mechanism of  “import from word, excel, google docs etc.” to actually upload a document from a different system. 
As shown in participant’s experience with task 2, Quizlet should set up a feature for presenting information in an addition to the medium of sets. Participant Z, a complete novice, was looking for classes as that system because that was a perceived mapping between world and system. Quizlet would tremendously increase their users if they accurately displayed their extensive information within their system. This improvement could involve a new search engine that not only searches within the sets not just the titles, but also presents the user with options to look for the information in classes, sets, and course content. 
While task 3 proved as very intuitive, since Quizlet usually has the information as to what school the user is in, it should offer a feature separate the sets by school, so people don’t have to just search psych 20a, they could also search “cognition” into the search engine for the specific school to get the class.  
In general, Quizlet would benefit from an improvement of more feedback on whether the feature in use is being used correctly, especially on whether the information was saved Participant X stated that to him, Quizlet felt like “a massive blackhole of information, I feel like it is going to break at any time and not sure if I am doing anything correctly because  there is no know safety.” This led participant X to see the helpfulness and confusion of that condition.
In creating feedback on the process of using Quizlet, they could also improve on incorporating feedback on the process of learning the material with Quizlet. As participant Z noted, “it just throws the information at you without teaching you what it is first.” Quizlet has some features installed like offering badges when the user completes a game but implementing metrics that demonstrate progress with a personal set, class, or topic has demonstrated useful in learning (Nicol & Macfarlane‐Dick, 2006). Not only would this better the learning for the user, but it would eradicate a violation of maxim of quality.  In task 3, participant Z received the feedback from the system saying that he is “getting the hang of this, I guess I am already good at this, without knowing anything.” This participant recognized that the system is deceiving him by stating that he knows something, even though he is aware he doesn’t actually know the material.

